# üèõÔ∏è Gothi-Read

**Track B:** *OCR + Font Group Recognition (Per-Character Multi-Task)*  
**Author:** Abdul Rafey  
**Repository:** https://github.com/rafeyshah/gothi-read

---

## üöÄ Overview

**Gothi-Read** is an end-to-end OCR + font-group recognition framework developed for **Pattern Recognition Lab**.
The goal is to build and benchmark models capable of:

1. **Optical Character Recognition** ‚Äî text transcription from scanned lines.
2. **Font Group Recognition** ‚Äî predicting the font category for every character.

The repository now provides:

* A verified, Unicode-safe data pipeline
* Manifest generation and integrity checks
* Visualization of font annotations
* Evaluation scripts with a unified model harness
* Metrics computation for CER/WER and font accuracy

---

## ‚öôÔ∏è Environment Setup

* Configured **Python 3 + PyTorch + Hugging Face + CUDA**.
* Verified GPU availability and reproducibility across Colab and VS Code.
* Modular directory layout: `scripts/`, `src/`, `notebooks/`, `runs/`.

Main dependencies:

```bash
pip install torch torchvision torchaudio transformers jiwer pillow regex matplotlib
```

---

## üßæ Dataset Handling and Validation

The data pipeline uses a **Unicode-safe, grapheme-based alignment strategy** to guarantee one-to-one correspondence between text and font labels.

### Canonical Unit Definition

`units.py` defines the **single source of truth** for all text processing:

* Unicode normalization: **NFC**
* Whitespace policy: layout whitespace removed, semantic spaces preserved
* Unitization: grapheme clusters via `regex \X`

These rules are applied **identically** to ground-truth text and `.font` annotations.

### Manifest Generation

`build_manifest.py` scans dataset folders and builds manifest CSVs using grapheme units:

* Reads raw `gt_text` from `.txt`
* Applies normalization + whitespace policy
* Splits text into grapheme units
* Reads `.font`, applies compatible normalization, and parses into font tokens
* Validates alignment: `len(gt_units) == len(gt_fonts)`

Each manifest row records:

```
id, image_path, gt_text,
 gt_units_len, font_units_len,
 ok, reason
```

### Clean Split Filtering

`filter_clean.py` filters manifests to keep only rows with `ok == TRUE`, producing `*_clean.csv` splits used for training and evaluation.

**Validation Integrity Summary (example)**

* Total lines : 4040
* Clean (ok=True) : 3827 (94.73 %)
* Missing txt : 213
* Length mismatches : 0

‚úÖ Clean splits are large and representative, not biased toward short or trivial strings.

---

## üß† Unified Model Evaluation Harness

`harness.py` provides a single interface to evaluate any OCR model while remaining compatible with **both legacy and current manifest schemas**.

### Supported Manifest Formats

1. **Legacy format**
   * `image_path` + `txt_path`
   * Ground truth text is read from disk

2. **Clean manifest format (current)**
   * `image_path` + `gt_text`
   * Ground truth text is read **directly from the CSV**

This ensures that `*_clean.csv` files generated by the grapheme-based pipeline work seamlessly with:

* `zeroshot_paddleocr.py`
* Fine-tuned PaddleOCR evaluation
* TrOCR / PARSeq / Donut benchmarks

**Outputs saved to**

```
runs/<model>/<date>/
  preds.txt
  metrics.json
  per_line.csv
```

---

## üìä OCR Benchmarks

### üîÅ Zero-Shot OCR Baselines

All zero-shot models were evaluated on the same **valid.csv** split using the unified evaluation harness.

| run                       | CER        | WER        |
|---------------------------|------------|------------|
| paddle-ocr-server-rec     | **0.2033** | **0.7551** |
| trocr-handwritten-beam    | 0.3567     | 2.1687     |
| paddle-ocr-mobile-rec     | 1.8355     | 1.4113     |
| trocr-handwritten-greedy  | 0.3835     | 2.3316     |
| trocr-large-printed       | 0.8403     | 5.1094     |
| donut-base-ocr            | 0.5965     | 1.0711     |
| parseq                    | 0.7040     | 0.9927     |
| abinet                    | 0.7576     | 0.9932     |
| vitstr                    | 0.7573     | 0.9934     |

---

### üß™ Fine-Tuned PaddleOCR

The strongest zero-shot model (**PaddleOCR ‚Äì server recognizer**) was fine-tuned for **5 epochs** on the training split and evaluated on `test.csv`.

**Evaluation metrics (lower is better):**

* **CER:** 0.0128 (~1.3 %)
* **WER:** 0.0796 (~8 %)

This represents a substantial improvement over the zero-shot baseline and serves as a strong CTC-based OCR reference for later ensembling and character-level font alignment.

---

## üîú Next Steps

* Fine-tune **TrOCR-handwritten** and select the primary OCR by lowest CER
* Add a font-classification head for per-character font prediction
* Ensemble CTC (PaddleOCR) and seq2seq (TrOCR) models
* Compute joint **text CER + font-CER** for final evaluation

---

## üèÅ Summary

**Gothi-Read** now includes a validated grapheme-based data pipeline, clean manifest generation, a schema-robust evaluation harness, and strong OCR baselines. The project is ready for multi-task font recognition and ensemble experiments.